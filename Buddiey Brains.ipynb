{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Buddiey Brains.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rdhingra001/buddiey/blob/master/Buddiey%20Brains.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLzmEM00tg_C"
      },
      "source": [
        "# Buddiey - The Brains\r\n",
        "\r\n",
        "Developed by the makers of Project: Buddiey ([Ronit](mailto:ronit@buddiey.live) more specifically)\r\n",
        "\r\n",
        "If viewed as PDF, runnable code can be found at: (https://www.buddiey.live/brain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkYtqPM93Hp5"
      },
      "source": [
        "## How It Was Made\r\n",
        "\r\n",
        "The \"Brains\" of Project: Buddiey, was developed with both two popular Deep Learning frameworks: Tensorflow & Keras.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C74wt0ttdOm"
      },
      "source": [
        "# Installing TensorFlow\r\n",
        "import sys\r\n",
        "!{sys.executable} -m pip install tensorflow\r\n",
        "!{sys.executable} -m pip install keras\r\n",
        "\r\n",
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf # A required module\r\n",
        "from keras.preprocessing.text import Tokenizer # An example module from Keras's text preprocessing libraries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGRlwtmuWgTn"
      },
      "source": [
        "\r\n",
        "\r\n",
        "These two modules allowed the backend developer for Project: Buddiey (Ronit) to create a Recurrent Neural Network (RNN), which is best specialized in text & speech analysis instead of the more widely used Convolutional Neural Network (CNN). So, he took the existing RNN architecture and made a model dedicated for Natural Language Processing (NLP), which would be able to extract the \"true\" message and emotion toward a sentence (a message thread for Buddiey). From there, it will use that extracted data and create a human-like sentence in response to the sentence or sent message.\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxJPSHLesF8X"
      },
      "source": [
        "### Natural Language Processing\r\n",
        "Natural Language Processing (NLP) is a capability in computing that analyzes the communication between human, or \"natural\" langauge, and computer language (programming languages). In most common scenarios, Natural Language Processing can be found in today's spellcheckers, autocompleters, and even some Telegram or Discord bots. These usually run on a type of neural network otherwise known as a RNN, or Recurrent Neural Network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1fUuWMtsCWs"
      },
      "source": [
        "### Recurrent Neural Networks\r\n",
        "Recurrent Neural Networks (RNN) is a specialized type of neural networks. These are most utilized for text and speech analysis, and are typically used alongside Natural Language Processing libraries and models. Unlike CNNs (Convolutional Neural Networks) which are better for image and video analysis, RNN is mostly implemented in conversational AI, and can be used to analyze the sentiment and message from a sentence or message."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPzK4kPjyJWM"
      },
      "source": [
        "## Bag of Words\r\n",
        "\r\n",
        "If you've done anything with Natural Language Processing and/or Recurrent Neural Networks, you're most likely going to have heard of the phrase \"bag of words\". If not, it's essentially the process of tokenizing a sentence and splitting up the words inside of a dictionary, and keeping count of each word in the given sentence. It can be very helpful for simple queries, but the quality starts to deteriorate once you feed the model complex inputs.\r\n",
        "\r\n",
        "### Downsides of the Bag of Words & Why Buddiey Doesn't Use It\r\n",
        "Let's look at two sentences to exploit some downsides:\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "I thought the movie was going to be bad, but it was great!\r\n",
        "```\r\n",
        "\r\n",
        "```\r\n",
        "I thought the movie was going to be great, but it was bad!\r\n",
        "```\r\n",
        "\r\n",
        "A typical model would split both these sentences into the same JSON structure:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tj22C-Df2s9J",
        "outputId": "ba520b09-13d9-4033-c77a-50f07a943074"
      },
      "source": [
        "vocab = {}\r\n",
        "word_encode = 1\r\n",
        "def bag_of_words(text):\r\n",
        "  global word_encode # It is not reccomended to use global keywords, I'm only using them for demonstration\r\n",
        "\r\n",
        "  words = text.lower().split(\" \")\r\n",
        "  bag = {}\r\n",
        "\r\n",
        "  # Iterates throught the words and see if it exists in the model vocabulary\r\n",
        "  for word in words:\r\n",
        "    if word in vocab:\r\n",
        "      encoding = vocab[word]\r\n",
        "    else:\r\n",
        "      vocab[word] = word_encode\r\n",
        "      encoding = word_encode\r\n",
        "      word_encode += 1\r\n",
        "    \r\n",
        "    if encoding in bag:\r\n",
        "      bag[encoding] += 1\r\n",
        "    else:\r\n",
        "      bag[encoding] = 1\r\n",
        "  \r\n",
        "  return bag\r\n",
        "\r\n",
        "movie_bad_great = \"I thought the movie was going to be bad but it was great\"\r\n",
        "movie_great_bad = \"I thought the movie was going to be great but it was bad\"\r\n",
        "bag_1 = bag_of_words(movie_great_bad)\r\n",
        "bag_2 = bag_of_words(movie_bad_great)\r\n",
        "print(f\"Model Vocabulary: {vocab}\")\r\n",
        "print(f\"First Review: {bag_1}\")\r\n",
        "print(f\"Second Review: {bag_2}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Vocabulary: {'i': 1, 'thought': 2, 'the': 3, 'movie': 4, 'was': 5, 'going': 6, 'to': 7, 'be': 8, 'great': 9, 'but': 10, 'it': 11, 'bad': 12}\n",
            "First Review: {1: 1, 2: 1, 3: 1, 4: 1, 5: 2, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1}\n",
            "Second Review: {1: 1, 2: 1, 3: 1, 4: 1, 5: 2, 6: 1, 7: 1, 8: 1, 12: 1, 10: 1, 11: 1, 9: 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARU9P-jJ4roX"
      },
      "source": [
        "When you run the code cell, you can see that these two sentences have two completely different motives, but the Bag of Words function collects them the same way. We can confirm that they equal the same with this script below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "DZL7XgRH5JWt",
        "outputId": "0bb0e35c-0785-4ae8-9350-b80c7bb85dc9"
      },
      "source": [
        "# Function to see if two elements equal each other\r\n",
        "def element_equal(bag1, bag2):\r\n",
        "  return bag1 == bag2\r\n",
        "\r\n",
        "equal = element_equal(bag_1, bag_2)\r\n",
        "print(equal)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dead8cd26a0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mbag1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbag2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mequal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbag_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbag_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bag_1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5__3n-F6Bw4"
      },
      "source": [
        "As seen when running the code cell right above this text box, we see that both bags returned from the function are equivalent, though both sentences have different intentions. For example, one of the sentences said that the movie they saw was bad, while the other said that the movie they saw was good. This small flaw can be fatal in ruining the user's experience with Buddiey, and we can't risk that. So, keep reading to see how our team optimized our model with newer and more accurate technologies instead for our Recurrent Neural Network and Natural Language Processing model.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21N70A4YxMNX"
      },
      "source": [
        "## Buddiey's Optimizations\r\n",
        "\r\n",
        "If you keep reading in this category, you will see replacements that the Buddiey team has implemented in their model. We implemented different neural nets and NLP algorithms rather than the traditional \"Bag of Words\" algorithm and other neural nets. Of course, I'm not going to say what they are (that's why there's a dedicated section), so keep reading to see what each part we changed and why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eegHyS9gpp7L"
      },
      "source": [
        "### Buddiey's NLP: Word Embeddings\r\n",
        "\r\n",
        "Luckily for us, there is another method that is far superior, accurate, and scalable that removes the need for the classic \"Bag of Words\". Rather than taking the words from a sentence and then assigning a word to the model's vocabulary at a random index, this method keeps the order of the words intact and takes the meaning and encodes each word into a dense vector that represents its context in the sentence, or message thread in our scenario.\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEmapOcZt5go"
      },
      "source": [
        "Think of it this way; we have four words: good, happy, sad, mad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c408IR55t8b2"
      },
      "source": [
        "On a traditional bag of words model, the indices for each word are mixed up, and are inputted depending on the order of them in a given phrase or sentence. \r\n",
        "\r\n",
        "For example:\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d723vDRmuxEo"
      },
      "source": [
        "sentence = \"Am I good or bad, or am I happy or sad?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6S63ICFu1fw"
      },
      "source": [
        "So we created a basic sentence with all four words incorporated with a given sentence. Now, let's see if we process this with our existing \"Bag of Words\" function and see what we get"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6G8dbL5vKfT",
        "outputId": "ce56d904-cc36-4aa9-e2cc-ff7360360be3"
      },
      "source": [
        "vocab = {}\r\n",
        "\r\n",
        "bag_sentence = bag_of_words(sentence)\r\n",
        "\r\n",
        "print(vocab)\r\n",
        "print(bag_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'am': 13, 'i': 14, 'good': 15, 'or': 16, 'bad,': 17, 'happy': 18, 'sad?': 19}\n",
            "{13: 2, 14: 2, 15: 1, 16: 3, 17: 1, 18: 1, 19: 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r426LhWFvb4Z"
      },
      "source": [
        "As you can see, the vocab dictionary classifies each word into the dictionary based on the order of the sentence, but not its meaning or connection with the other existing words in that sentence. This can prove to be fatal in production, since the model would have a very high probability of making mistakes in its NLP core and confuse the user, may it be a chatbot, autocorrect, or even a text-to-speech program."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x59ZGYo3Yg7"
      },
      "source": [
        "### SimpleRNN - Simple Recurrent Layer\r\n",
        "\r\n",
        "As you can tell from the name, a SimpleRNN is a layer that belongs to a Recurrent Neural Network. As the name suggests, this process is simple and it only gets more complex from here.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpgmOP2d5Xuq"
      },
      "source": [
        "Rather than taking all of the data at once and processing it from left to right, the SimpleRNN splits the words, uses the \"Word Embeddings\" algorithm, uses the returned vector and converts it to a numeric value that is usable for the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KYimYLA5tkt"
      },
      "source": [
        "Let's use an example of:\r\n",
        "```\r\n",
        "sentence = \"Hi I am Buddiey\"\r\n",
        "```\r\n",
        "\r\n",
        "Since this sentence has four different words, the layer will assign 4 cells to process the sentence. To better understand the process of this, there are two crucial steps that are thoroughly explained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQV6p-lR7LEl"
      },
      "source": [
        "#### Split The Sentence\r\n",
        "\r\n",
        "This is typically done with a simple algorithm which grabs each word from a sentence and saves them in a list for reference.\r\n",
        "\r\n",
        "```\r\n",
        "words = [\"hi\", \"i\", \"am\", \"buddiey\"]\r\n",
        "```\r\n",
        "\r\n",
        "It is important that this is firstly done because the neural network layer requires a single word as an input, and doesn't accept an entire sentence. Also, we are using the more efficient \"Word Embeddings\" algorithm instead of \"Bag Of Words\", which requires for the Natural Language Processing procedure to have the given input split up into words, and then later cached as vectors for finding the intent, or meaning of a query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9gMF1tLYEcx"
      },
      "source": [
        "# How it's done\r\n",
        "sentence = \"Hi I am Buddiey\"\r\n",
        "words = sentence.lower().split(\" \") # [\"hi\", \"i\", \"am\", \"buddiey\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBfjSRXGVfQ_"
      },
      "source": [
        "#### Process Each Word\r\n",
        "\r\n",
        "From now, all the SimpleRNN needs to do to make it possible for the model to use the data is to process each word from the sentence and return the query as a combination of numerical computations, which are retrieved by flattening the retreived vectors from the \"Word Embeddings\" algorithm. \r\n",
        "\r\n",
        "Since there are 4 words inside of the given sentence, the RNN layer will assign 4 cells to compute the intent and use NLP to calculate data. The first cell will take in the first word as an input and compile it to a vector, then converted to a numerical unit for further usage. For the second cell, the output from the first one, along with the second word, gets inputted and the same procedure happens. The process keeps looping like this for every cell until every word gets indexed.**bold text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiJ2otOFc1wz"
      },
      "source": [
        "# Note: The following lines of code are invalid, and do not have any computational value. It is only to show how each word gets indexed.\r\n",
        "\r\n",
        "def process_word(word) -> Num # Takes in a word and returns a numerical value\r\n",
        "cell1 = process_word(words[0])\r\n",
        "cell2 = cell1 + process_word(words[1])\r\n",
        "cell3 = cell2 + process_word(words[2])\r\n",
        "cell4 = cell3 + process_word(words[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYfsTw-0K6KZ"
      },
      "source": [
        "```\r\n",
        "(Example) Output: Cells successfully created and ready to use\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTehgeARw01C"
      },
      "source": [
        "### LSTM - Long/Short Term Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7zS5nQVL3KA"
      },
      "source": [
        "The LSTM, or Long/Short Term Memory layer, is another layer that can be found or added to a Recurrent Neural Network. However, it greatly differs from a SimpleRNN layer. This is because, as the name suggests, the layer has a memory of sorts and can retreive any data from previous timestamps. In the SimpleRNN layer, the previous data would gradually disappear and would proritize the next layer or the layer in progress. But, the LSTM can retrieve data from the past, which can be valuable when Buddiey refers data from previous discussions, and remembers these conversations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPbo_DBcOCyv"
      },
      "source": [
        "**Note:** Because the blueprints of both LSTM and SimpleRNN are so similar, I'm not going to supply code snippets for this in actual progress."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Lcz2aXuOc80"
      },
      "source": [
        "## How it Works\r\n",
        "\r\n",
        "I could have put this at the beginning of this Jupyter Notebook (or Google Colab or PDF), but I decided that I should explain what tools are used in depth, then explain how they all come together. Sorry for making you read all of this 😛"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ97-bt-RQBu"
      },
      "source": [
        "## Buddiey - Making the Brains\r\n",
        "\r\n",
        "Ok, so you know how everything fits into place, and why in the end I wrote in thorough detail about all of the concepts, from the \"Bag of Words\" to the \"LSTM\". So, now I'll start writing the code and explain how they relate to my initial explanation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMSmWq4PQhsH"
      },
      "source": [
        "### Importing Our Datasets\r\n",
        "\r\n",
        "The first part in any RNN or NLP based solution is to import the datasets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "R6-juxYHrRVG",
        "outputId": "97c99d9b-fbef-493b-b836-0b93fc10a462"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "link = \"https://app.buddiey.live/resources/\"\r\n",
        "df = pd.read_csv(link + \"buddiey-training.tsv\", sep='\\t', header=None)\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Florida doesn't have earthquakes or fires.</td>\n",
              "      <td>No, florida just has hurricanes every year fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What's your name ?</td>\n",
              "      <td>My name is marfa and i can be your best friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Would you put suntan lotion on my back, please?</td>\n",
              "      <td>Sure.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the purpose of living ?</td>\n",
              "      <td>To live forever .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>My pants have a hole in the front pocket.</td>\n",
              "      <td>You shouldn't carry pens in your pocket.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>The only thing in my backpack is used books.</td>\n",
              "      <td>But thieves don't know that.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>I hate you</td>\n",
              "      <td>Why? what have i done to derserve this? can't ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>I am happy, but marriage is a lot of responsib...</td>\n",
              "      <td>Yes, you have to take care of your wife.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>What is your best childhood memory ?</td>\n",
              "      <td>When we were kids , we had our own a secret la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>It seems like i get a new pimple almost every ...</td>\n",
              "      <td>Maybe it's something in your diet.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>509 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     0                                                  1\n",
              "0           Florida doesn't have earthquakes or fires.  No, florida just has hurricanes every year fro...\n",
              "1                                   What's your name ?     My name is marfa and i can be your best friend\n",
              "2      Would you put suntan lotion on my back, please?                                              Sure.\n",
              "3                      What is the purpose of living ?                                  To live forever .\n",
              "4            My pants have a hole in the front pocket.           You shouldn't carry pens in your pocket.\n",
              "..                                                 ...                                                ...\n",
              "504       The only thing in my backpack is used books.                       But thieves don't know that.\n",
              "505                                         I hate you  Why? what have i done to derserve this? can't ...\n",
              "506  I am happy, but marriage is a lot of responsib...           Yes, you have to take care of your wife.\n",
              "507               What is your best childhood memory ?  When we were kids , we had our own a secret la...\n",
              "508  It seems like i get a new pimple almost every ...                 Maybe it's something in your diet.\n",
              "\n",
              "[509 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    }
  ]
}